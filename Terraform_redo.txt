-------------------------
Terraform
-----------------------

Инструмент для создания инфраструктуры как код.

---------
Установка
---------

https://learn.hashicorp.com/tutorials/terraform/install-cli

Установка происходит легко.


----------------
Плагины для Atom
----------------

Какие же нужны плагины под Atom:
- language-terraform;
- terraform-fmr;
- linter-terraform-syntacs

----------------------------------------------------------------------
Инициализация проекта.
Создание, удаление и изменение ресурса в AWS на примере EC2 instance'а
----------------------------------------------------------------------

---------------------
Инициализация проекта
---------------------

Перед тем как начинать создавать ресурсы, мы должны понять как работает terraform.
При запуске на выполнение, terraform ищет все файлы с суффиксом - tf в рабочей директории.
В связи с этим для каждого проекта, нужно создать отдельную директорию,
где будут храниться все tf файлы проекта.

$ mkdir ./001_Create_AWS_EC2_instance; cd ./001_Create_AWS_EC2_instance

В terraform для начала, нужно описать провайдера в котором мы будем создавать ресурс.
У нас в качестве провайдера будет выступать AWS.

Как же описывать провайдера? Да и вообще как найти документацию о том как что-то делать для определенного провайдера?
Легко, нужно найти его на официальном сайте (https://registry.terraform.io/browse/providers) и посмотреть документацию.
Вот ссылка на документацию - https://registry.terraform.io/providers/hashicorp/aws/latest/docs

Создадим tf файл с описанием провайдера. Название может быть произвольное.
Тут довольно таки все понятно. Стоит только отметить, что с помощью shared_credentials_files
мы указываем путь к файлу с настройками доступа к AWS.
Данный файл создается когда вы пользуетесь AWS CLI.

********************************************************************************
Отсупление:
https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html
По этой ссылке можно посмотреть как установить AWS CLI. После установки, нужно

$ aws configure

Далее, ввести актуальные ключи.

Вот подробней

https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html

********************************************************************************

$ touch ./aws_provider.tf

terraform {
  required_providers {
    aws = {
      source = "hashicorp/aws"
    }
  }
}

provider "aws" {
  region = "eu-central-1"
  shared_credentials_files = ["~/.aws/credentials"]
  profile = "default"
}


Далее, инициализируем terraform проект

$ terraform init

Initializing the backend...

Initializing provider plugins...
- Finding latest version of hashicorp/aws...
- Installing hashicorp/aws v4.13.0...
- Installed hashicorp/aws v4.13.0 (signed by HashiCorp)

Terraform has created a lock file .terraform.lock.hcl to record the provider
selections it made above. Include this file in your version control repository
so that Terraform can guarantee to make the same selections by default when
you run "terraform init" in the future.

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.

$ ls -la
total 20
drwxrwxr-x 3 denisb denisb 4096 мая  7 08:53 .
drwxrwxr-x 5 denisb denisb 4096 мая  7 08:44 ..
-rw-rw-r-- 1 denisb denisb  210 мая  7 08:47 aws_provider.tf
drwxr-xr-x 3 denisb denisb 4096 мая  7 08:53 .terraform
-rw-r--r-- 1 denisb denisb 1152 мая  7 08:53 .terraform.lock.hcl

-------------------------------------------
Указать учетные данные с помощью переменных
-------------------------------------------

Отдельно стоит отметить, что мы использовали ~/.aws/credentials в качестве учетных
данных. Хочу показать еще один расспространенный способ, который более предпочтительный,
т.к. над tf файлом могут работать разные люди у которых, например файл ~/.aws/credentials
может называться по-другому или вообще отсувствовать.

Еще одним способом указания учетных данных - является объявление некоторых переменных.
Ну и конечно создание для terraform отдельного пользователя в AWS с ограниченными правами.


$ export AWS_ACCESS_KEY_ID=<your access key id>
$ export AWS_SECRET_ACCESS_KEY=<your secret access key>
$ export AWS_DEFAULT_REGION=<your default region>

При этом файл с описанием провайдера, в нашем случае - aws_provider.tf, будет
иметь другой вид

terraform {
  required_providers {
    aws = {
      source = "hashicorp/aws"
    }
  }
}

provider "aws" {}

----------------------------------------
Создание ресурса (EC2 Instance'а)
----------------------------------------

Вот все параметры как создавать данный ресурс
https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/instance

Создадим файл, в котором будем создавать ресурс. Название может быть произвольное.
Тут тоже должно быть все понятно

$ touch ./main.tf

resource "aws_instance" "my_amazon_linux" {
  ami = "ami-05f5f4f906feab6a7"
  instance_type = "t2.micro"

  key_name = "bochinskii_Frankfurt_2"

  vpc_security_group_ids = [
    "sg-004c28689f21a4a77",
    "sg-061ddb8453ccbf935"
  ]
  availability_zone = "eu-central-1a"
  subnet_id = "subnet-000c2008b7496a3b7"

  root_block_device {
    volume_type = "gp3"
    volume_size = 15
    delete_on_termination = true
  }

  tags = {
    Name = "my_amazon_linux"
    Owner = "Denis Bochinskii"
  }
}

Далее, проверим синтаксис и получим вывод, что terraform должен будет сделать.
На данном этапе можно все проверить и если вы ошиблись, то поправить определенные
tf файлы.

$ terraform plan

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

...

Plan: 1 to add, 0 to change, 0 to destroy.

Далее, выполняем tf файлы

$ terraform apply

...

Plan: 1 to add, 0 to change, 0 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

aws_instance.my_amazon_linux: Creating...
aws_instance.my_amazon_linux: Still creating... [10s elapsed]
aws_instance.my_amazon_linux: Still creating... [20s elapsed]
aws_instance.my_amazon_linux: Still creating... [30s elapsed]
aws_instance.my_amazon_linux: Still creating... [40s elapsed]
aws_instance.my_amazon_linux: Creation complete after 46s [id=i-0da179ee934358a97]

Apply complete! Resources: 1 added, 0 changed, 0 destroyed.


Вот какой файл - terraform.tfstate появился после того, как мы выполнили команду - apply.

$ ls -l
total 16
-rw-rw-r-- 1 denisb denisb  210 мая  7 08:47 aws_provider.tf
-rw-rw-r-- 1 denisb denisb  426 мая  7 10:37 main.tf
-rw-rw-r-- 1 denisb denisb 4236 мая  7 10:41 terraform.tfstate

В нем находится вся информация о том, что сделано в данный момент в данном проекте.
Поэтому если мы запустим команду apply снова, terraform выдаст информацио о том,
что ничего создавать не нужно. Напомню, что эту информацию он берет из файла -
terraform.tfstate. Теперь можно сделать вывод, что файл terraform.tfstate очень важен.

$ terraform apply
aws_instance.my_amazon_linux: Refreshing state... [id=i-01168c67a974a129e]

No changes. Your infrastructure matches the configuration.

Terraform has compared your real infrastructure against your configuration and found no differences, so no changes are needed.

Apply complete! Resources: 0 added, 0 changed, 0 destroyed.


Давайте добавим еще одну кoнфигурацию ресурса в файл - main.tf. Создадим такой-же
ресурс, только в другой AZ

resource "aws_instance" "my_amazon_linux_2" {
  ami = "ami-05f5f4f906feab6a7"
  instance_type = "t2.micro"

  key_name = "bochinskii_Frankfurt_2"


  vpc_security_group_ids = [
    "sg-004c28689f21a4a77",
    "sg-061ddb8453ccbf935"
  ]
  availability_zone = "eu-central-1b"
  subnet_id = "subnet-0646580d441af171c"

  root_block_device {
    volume_type = "gp3"
    volume_size = 10
    delete_on_termination = true
  }

  tags = {
    Name = "my_amazon_linux"
    Owner = "Denis Bochinskii"
  }
}

$ terraform plan

Как мы видим, terrform знает, что ресурс my_amazon_linux уже создан,
а значит нужно создать только ресурс - my_amazon_linux_2. Таким образом у нас
запущены 2-а ec2 instance'а.

$ terraform apply

Plan: 1 to add, 0 to change, 0 to destroy.

...

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

aws_instance.my_amazon_linux_2: Creating...
aws_instance.my_amazon_linux_2: Still creating... [10s elapsed]
aws_instance.my_amazon_linux_2: Still creating... [20s elapsed]
aws_instance.my_amazon_linux_2: Still creating... [30s elapsed]
aws_instance.my_amazon_linux_2: Creation complete after 38s [id=i-046fcb00b46b64106]

*****************************************************************************************
Важно:
Если мы сейчас удалим файл - terraform.tfstate и запустим apply снова. то terraform
не будет знать о созданной им информатруктуре и начнет создавать эти два ресурса заново.
*****************************************************************************************


-----------------
Удаление ресурсов
-----------------


Один из вариантов - это удалить ненужный ресурс в tf файле. И запустить команду - apply.
Этот вариант хорошб, если вам нужно удалить определенный ресурс, который стал не нужен.

Удалим ресурс - my_amazon_linux_2 из main.tf файла

Теперь выполним команду plan.
Мы видим, что terrafom будет удалять ресурс my_amazon_linux_2

$ terraform plan
aws_instance.my_amazon_linux_2: Refreshing state... [id=i-046fcb00b46b64106]
aws_instance.my_amazon_linux: Refreshing state... [id=i-01168c67a974a129e]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  - destroy

Terraform will perform the following actions:

  # aws_instance.my_amazon_linux_2 will be destroyed
  # (because aws_instance.my_amazon_linux_2 is not in configuration)

  ...

Plan: 0 to add, 0 to change, 1 to destroy.

$ terraform apply

Ну, а что если не нужно изменять конфигурацию в tf файлах, но инфраструктуру нужно
удалить.

$ terraform destroy

Таким образом мы удалили все ресурсы описанные в tf файлах данного проекта (директории).

------------------
Изменение ресурсов
------------------

К этому времени уможе должно быть понятно, что изменять ресурсы можно изменяя код в
tf файлах, а потом выполнить команду - apply.


-----------------------------------------------
Зависимости и использование перемнных окружения
-----------------------------------------------

Создадим новый проект

$ mkdir ./002_Create_LEMP_file; cd ./002_Create_LEMP_file

Оставим "за кадром" создание конфигурации провайдера.

Экспортируем все необходимые переменные.

$ export AWS_ACCESS_KEY_ID=<your access key id>
$ export AWS_SECRET_ACCESS_KEY=<your secret access key>
$ export AWS_DEFAULT_REGION=<your default region>

Экспорт данной переменной, будет объяснен ниже.

$ export TF_VAR_ssh_port=<your custome ssh port number>

-----------
Зависимости
-----------

Существуют автоматические зависимости и не автоматические.

Автоматические зависимости посмотрим на примере создания LEMP сервера к которому будет "привязаны"
две новосозданные группы безопасности.

$ touch main.tf

Так как файл имеет внушительное количество содержимого, ознакомится с ним вы можете
в директории с проектом.

В tf файле мы сперва укзали ресур aws_instance, а потом ресурсы aws_security_group.
Тем не менее мы создали автоматическую зависимость между aws_instance и aws_security_group
путем указания - aws_security_group.my_lemp_web.id и aws_security_group.my_lemp_ssh.id:

vpc_security_group_ids = [
  aws_security_group.my_lemp_web.id,
  aws_security_group.my_lemp_ssh.id
]

т.е. terraform просканировал tf файл и выяснил, что есть зависимость между ресурсами и таким образом
сначала создал группы безопасности, а потом уже ресурс с ec2 instance'ом.

********************************************
Заметка:

Рассмотрим как мы указали группы безопаности на примере одной - aws_security_group.my_lemp_web.id.
Эта запись состоит из названия ресурса (aws_security_group), его имени (my_lemp_web)
и одентификационного номера (id).

На самом деле можно "забрать" не только id, но и некоторые другие параметры.
Их можно найти в документации.

Если посмотреть на документацию по AWS - https://registry.terraform.io/providers/hashicorp/aws/latest/docs
то можно заметить, что документация о AWS сервисах, подразделяется на:
- resources
- data source
В resources описывается документация и параметры ресурса, а в data source
описывается то, что можно получить в качетсве переменной от созданного ресурса.

Вот data source документация например для группы безопасности -
https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/security_group
********************************************

Не автоматические зависимости рассмотрим без практики.

Они используются, когда нет возможности использовать автоматические.

Например, нужно создать три ec2 instance'а, но чтобы один из них (database) создался первый.
А еще один из них (web) должен создасться позже всех.

resource "aws_instance" "web" {
  ...
  depends_on = [
    aws_instance.database,
    aws_instance.application,
  ]

}

resource "aws_instance" "application" {
  ...
  depends_on = [
    aws_instance.database,
  ]

}

resource "aws_instance" "database" {
  ...

}

Таким образом terraform "увидит", что database не от кого не зависит и создасться
первым. Ресурс web зависит от двух ресурсов (database, application), поэтому он создастся
последним.

------------------------------------------
Использование перемнных окружения (TF_VAR)
------------------------------------------


https://www.terraform.io/language/values/variables

Далее, рассмотрим использование переменных окружения в tf файле.
Например, мы не захотели, чтобы в tf файле был показан
кастомный ssh порт. Как мы вышли из положения?

Как вы видели выше мы экспортровали вот такую переменную - TF_VAR_ssh_port,
в которой указали номер порта. Чтобы ее использовать в tf файле,
мы указали var.ssh_port в ресурсе группы безопасности.

Но этого мало. Еще нужно создать "мост" между tf файлом и вашим перемнным окружения.
Это делается с помощью объявления пустой переменной в tf файле:

variable "ssh_port" {}

https://www.terraform.io/language/functions/file

Ну и отметим, что мы использовали скрипт в base64 кодировке, для установки
LEMP. За это отвечает параметр - user_data_base64 в ресурсе - aws_instance.

Так же важным моментом является то, что если мы изменим user data скрипт и запустим
apply снова, что terraform поймет, что измнился скрипт и пересоздаст ec2 instance.


----------------------------------------------
Вывод на экран информации о ресурсах (outputs)
----------------------------------------------

https://www.terraform.io/language/values/outputs

https://www.terraform.io/cli/commands/output

Есть вещи, которые нужно вывести на экран после создания. На самом деле outputs
могут еще использоваться для того, чтобы их значение занести в переменные.

Сейчас мы рассмотрим, только вывод на экран. Зачем это может понадобится?
Вот в нашем примере мы создали LEMP. Теперь, нам нужно зайти по его
ip или dns. Можно воспользоваться AWS консолью. Но, что если у нас нет доступа
к консоли.

В файле ./outputs.tf находятся наши outputs'ы. Мы выведем публичный ip адрес,
публичный dns, ну и просто, выведем, arn ec2 instance'а.

Вот пример:

output "aws_instance_my_lemp_public_ip" {
  value = aws_instance.my_lemp.public_ip
}

aws_instance_my_lemp_public_ip - это произвольное имя output'а.

Эта конструкция нам известна:

value = aws_instance.my_lemp.public_ip

Напомню, что все данные, которые можно вывести можно найти в документации, в
разделе data sources. Или когда выполняете команду - plan. На экран выводится информация
о ресурсах. Все что там указано, можно вывести с помощью outputs'ов.


$ terraform init

$ terraform plan

$ terraform apply

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:
...
Plan: 3 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + aws_instance_my_lemp_arn        = (known after apply)
  + aws_instance_my_lemp_public_dns = (known after apply)
  + aws_instance_my_lemp_public_ip  = (known after apply)
  Do you want to perform these actions?
    Terraform will perform the actions described above.
    Only 'yes' will be accepted to approve.

    Enter a value: yes

aws_security_group.my_lemp_web: Creating...
aws_security_group.my_lemp_ssh: Creating...
aws_security_group.my_lemp_web: Creation complete after 7s [id=sg-052d8b7d369e8b024]
aws_security_group.my_lemp_ssh: Creation complete after 8s [id=sg-02fcde201a9e970af]
aws_instance.my_lemp: Creating...
aws_instance.my_lemp: Still creating... [10s elapsed]
aws_instance.my_lemp: Still creating... [20s elapsed]
aws_instance.my_lemp: Still creating... [30s elapsed]
aws_instance.my_lemp: Still creating... [40s elapsed]
aws_instance.my_lemp: Creation complete after 49s [id=i-0907327f3c5f837d1]

Apply complete! Resources: 3 added, 0 changed, 0 destroyed.

Outputs:
aws_instance_my_lemp_arn = "arn:aws:ec2:eu-central-1:880954070217:instance/i-0907327f3c5f837d1"
aws_instance_my_lemp_public_dns = "ec2-54-93-118-67.eu-central-1.compute.amazonaws.com"
aws_instance_my_lemp_public_ip = "54.93.118.67"


Как мы видим, после того, как ресурсы создались у нас на экране вывелись значения
"наших" outputs'ов.

Кстати, после того как выполнился apply мы можем посмотреть на наши otputs'ы
с помощью команды:

$ terraform output
aws_instance_my_lemp_arn = "arn:aws:ec2:eu-central-1:880954070217:instance/i-0907327f3c5f837d1"
aws_instance_my_lemp_public_dns = "ec2-54-93-118-67.eu-central-1.compute.amazonaws.com"
aws_instance_my_lemp_public_ip = "54.93.118.67"


Не забываем, что удалить ресурсы вот так

$ terraform destroy


----------------------------------------------------------------------
Использование переменных, динамические блоки и шаблоны (templatefile)
----------------------------------------------------------------------

Создадим новый проект:

$ mkdir 003_Create_LEMP_templatefile; cd 003_Create_LEMP_templatefile/

Оставим "за кадром" создание конфигурации провайдера.

Экспортируем все необходимые переменные.

$ export AWS_ACCESS_KEY_ID=<your access key id>
$ export AWS_SECRET_ACCESS_KEY=<your secret access key>
$ export AWS_DEFAULT_REGION=<your default region>

$ export TF_VAR_ssh_port=<your custome ssh port number>
$ export TF_VAR_mysql_root_pass=<your mysql root password>
$ export TF_VAR_mysql_admin_user=<your mysql admin username>
$ export TF_VAR_mysql_admin_user_pass=<your mysql admin password>
$ export TF_VAR_mysql_drupal_user=<your mysql drupal username>
$ export TF_VAR_mysql_drupal_user_pass=<your mysql drupal user password>
$ export TF_VAR_mysql_drupal_db=<your mysql drupal database>
$ export TF_VAR_site_dir=<your prefix site directory>

Опять же, изучать переменные и шаблоны будем на примере создания LEMP к которому
будут привязаны 2 ново созданные группы безопасности.

------------------------
Использование переменных
------------------------

https://www.terraform.io/language/values/variables

Для начала создадим отдельный файл с переменными. Это - best practice.

$ touch ./variables.tf

С содержимым данного файла можно ознакомиться в директории с проектом.

У нас есть переменные, которые мы можем "показывать" в нашем проекте, а есть,
которые мы не хотим "показывать". Как бы там нибыло, мы должны определить все переменные.
Просто, те переменные, которые мы будем брать из переменных окружения мы определяем как пустые.

Стоит упомянуть, что переменные типа list (в нашем случае переменная имеет имя - pkgs)
и map (в нашем случае переменная имеет имя - template_tags) очень похожи.
Отличия в том, что list - это просто список, а map - имеет ключ и значение.

Переменные типа - string и number понятны без объяснения.

-------------------------------------------------------------------------------
Консолидируем по переменным:

Для того, чтобы использовать переменные окружения, их нужно определить, сделать
экспорт и использовать.

Например:

$ export TF_VAR_ssh_port=<port number>

$ nano variables.tf

variable "ssh_port" {}

$ nano main.tf

resource "aws_security_group" "my_lemp_ssh" {
  ...
  ingress {
    ...
    from_port        = var.ssh_port
    to_port          = var.ssh_port
    ...
  }
...
}


Для того, чтобы использовать переменные, их нужно определить и использовать.

Например:

$ nano variables.tf

variable "ami" {
  type = string
  default = "ami-05f5f4f906feab6a7"
}

$ nano main.tf

resource "aws_instance" "my_lemp" {
  ami = var.ami
  ...
}
-------------------------------------------------------------------------------

Создаем ft файл для ресурсов

$ touch ./main.tf

С содержимым данного файла можно ознакомиться в директории с проектом.

Как мы уже говорили, обращаемся к переменным с помощью - var.<variable name>.

Тут стоит остановиться на конструкции:

tags = merge(
  var.template_tags,
  {
    Name = "my_lemp_${var.template_tags["Env"]}"
  }
)

https://www.terraform.io/language/functions/merge

Т.к. у нас есть теги одинаковый для всех ресурсов, то их удобно объявить в переменной
(в нашем случае с именем - template_tags), как мы и сделали. Но, у нас есть тэг отличающиеся
в зависимости от ресурсов (в нашем случае тэг - Name).

Для этого мы использовали функцию - merge. Она для объединения. Т.е. мы объединяем
два map. Одна объявлена с помощью переменной, а вторая map указана непосредственно
в функции.

Вот пример:

tags = merge(
  var.template_tags,
  {
    Name = "my_lemp_web"
  }
)

Так же примечательна конструкция:

Name = "my_lemp_${var.template_tags["Env"]}"

Тут мы указали имя (my_lemp_) + суффикс (${var.template_tags["Env"]}),
который берется из переменной template_tags, а именно из ключа - Env.

------------------
Динамические блоки
------------------

https://www.terraform.io/language/expressions/dynamic-blocks

Динамические блоки лучше использовать в редких исключениях, когда код ресурса не
сложный. Использования динамических блоков может привести к сложной читаемости кода.
Эти слова указаны в официальной документации terraform.

В нашем пимере мы использовали динамические блоки чтобы открыть дополнительные
порты в группе безопасности - my_lemp_web. В данном случае динамоческие блоки
хорошо подходят т.к. нам нужно открыть дополнительно 4 порта и без блоков, нам бы пришлось
описивать 4 дополнительных директивы - ingress. А теперь представьте, что нам нужно
добавить не 4 дополнительных порта, а 24. В подобных ситуациях динамические блоки
хорошо могут выручить.

Что мы сделали? В файле variables.tf мы объявили список:

variable "ingress_my_lemp_web" {
  type =list(number)
  default = [8080, 4343, 8180, 8181]
}

а в файле main.tf использовали динасический блок в ресурсе - my_lemp_web:

  dynamic "ingress" {
    for_each = var.ingress_my_lemp_web
    content {
      from_port        = ingress.value
      to_port          = ingress.value
      protocol         = "tcp"
      cidr_blocks      = ["0.0.0.0/0"]
      ipv6_cidr_blocks = ["::/0"]
    }


--------------------------------------------------
Использование шаблонов (templatefile)
--------------------------------------------------

https://www.terraform.io/language/functions/templatefile


В прошлый раз мы использовали функцию - file("<path to the shell script>").
Таким образом мы использовали статический файл (скрипт) для установки LEMP.

Но можно использовать не статический файл, а динамически создаваемый (шаблоны).
Для чего это может понадобится? Например, в нашем случае в скрипте используются
переменные, в которых должны быть определены пароли для базы данных. Эти переменные
не хочется указывать в скрипте в плейн тексте. Поэтому мы будем использовать шаблон.

Вот как он используется:

user_data = templatefile("<path to temple file>", {var1 = <value>, var2 = <value>, ... })

Тут, переменные которые будут использоваться в шаблоне (скрипте).

Шаблон - это обычный скрипт на shell, но мы можем использовать там переменные,
которые могут быть использованы terraform'ом. Бест практис,
добавлять суффикс к названию файла - "tftpl".

В директории с проектом можете ознакомится со скриптом - user_data.sh.tftpl.

Тут приведем только некоторые примеры. Вот кусочек кода скрипта:

export SSH_PORT=${ssh_port}

данная переменная - "${ssh_port}" определяется в файле variables.tf:

variable "ssh_port" {}

которая в данном случае берет переменную из окружения:

export TF_VAR_ssh_port=<your ssh port number>

В файле main.tf мы указывали файл шаблон с переменными, которые должны будут использованы
в скрипте:

user_data_base64 = base64encode(templatefile("./user_data.sh.tftpl",
{
  ...
  ssh_port = var.ssh_port,
  ...
}
))

Тут есть нюанс, в дополнение к функции "templatefile" мы использовали - "base64encode".
Данная функция нужно для преобразования шиблона в base64 кодировку.

https://www.terraform.io/language/functions/base64encode

Вот еще один пример. В скрипте есть такие строчки:

%{ for p in pkgs ~}
yum install ${p} -y
%{ endfor ~}

Переменная - pkgs - это переменная типа list, которая определеная в файле variables.tf.
В данный список мы указали php пакеты, которые должны будут установлены.

Опять же, в файле main.tf мы определили данную переменную:

user_data_base64 = base64encode(templatefile("./user_data.sh.tftpl",
{
  ...
  pkgs = var.pkgs,
  ...
}
))

При таком подходе возникает сложность, которая состоит в том, что не всегда
очевидно какой файл сгенерируется. Вдруг мы там сделали ошибку. Для решение этой сложности
есть команда - console.

Проверить файл шаблона, а именно, правильно ли он поставит переменные.
На выходе мы получис наш скрипт, но с указанными значениями переменных.

$ terraform console

templatefile("./user_data.sh.tftpl", {hostname = var.hostname, timezone = var.timezone, ssh_port = var.ssh_port, mysql_repo = var.mysql_repo, mysql_root_pass = var.mysql_root_pass, mysql_admin_user = var.mysql_admin_user, mysql_admin_user_pass = var.mysql_admin_user_pass, mysql_drupal_user = var.mysql_drupal_user, mysql_drupal_user_pass = var.mysql_drupal_user_pass, mysql_drupal_db = var.mysql_drupal_db, pkgs = var.pkgs, ssl_cert = var.ssl_cert, ssl_key = var.ssl_key, site_dir = var.site_dir, site_config = var.site_config})

--------------------------------------------------------------------------------
Важно:
В консоль нужно ввести функцию в одну строчку.
--------------------------------------------------------------------------------

Далее запускаем создание нашей инфраструктуры.

$ terraform init

$ terraform plan

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:
...


$ terraform apply

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:
...

aws_security_group.my_lemp_ssh: Creating...
aws_security_group.my_lemp_web: Creating...
aws_security_group.my_lemp_ssh: Creation complete after 7s [id=sg-04ecc33418555be80]
aws_security_group.my_lemp_web: Creation complete after 8s [id=sg-047b9be33c405b34e]
aws_instance.my_lemp: Creating...
aws_instance.my_lemp: Still creating... [10s elapsed]
aws_instance.my_lemp: Still creating... [20s elapsed]
aws_instance.my_lemp: Creation complete after 30s [id=i-0465f3d4819a759e2]


$ terraform destroy

aws_security_group.my_lemp_ssh: Refreshing state... [id=sg-04ecc33418555be80]
aws_security_group.my_lemp_web: Refreshing state... [id=sg-047b9be33c405b34e]
aws_instance.my_lemp: Refreshing state... [id=i-0465f3d4819a759e2]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  - destroy

Terraform will perform the following actions:
...




--------------------------
Переопределение переменных
--------------------------

Вы могли заметить, что переменные определяются в - default.
Это значит, что они могут быть переопределены.

Вот пример:

Давайте, снова запустим plan в директории проекта и обратим внимание на ami и instance_type

$ terraform plan

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # aws_instance.my_lemp will be created
  + resource "aws_instance" "my_lemp" {
      + ami                                  = "ami-05f5f4f906feab6a7"
      + arn                                  = (known after apply)
      + associate_public_ip_address          = (known after apply)
      + availability_zone                    = "eu-central-1a"
      + cpu_core_count                       = (known after apply)
      + cpu_threads_per_core                 = (known after apply)
      + disable_api_termination              = (known after apply)
      + ebs_optimized                        = (known after apply)
      + get_password_data                    = false
      + host_id                              = (known after apply)
      + id                                   = (known after apply)
      + instance_initiated_shutdown_behavior = (known after apply)
      + instance_state                       = (known after apply)
      + instance_type                        = "t2.micro"
      ...

Теперь переопределим их:

$ terraform plan -var="ami=ami-09439f09c55136ecf" -var="instance_type=t3.micro"

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # aws_instance.my_lemp will be created
  + resource "aws_instance" "my_lemp" {
      + ami                                  = "ami-09439f09c55136ecf"
      + arn                                  = (known after apply)
      + associate_public_ip_address          = (known after apply)
      + availability_zone                    = "eu-central-1a"
      + cpu_core_count                       = (known after apply)
      + cpu_threads_per_core                 = (known after apply)
      + disable_api_termination              = (known after apply)
      + ebs_optimized                        = (known after apply)
      + get_password_data                    = false
      + host_id                              = (known after apply)
      + id                                   = (known after apply)
      + instance_initiated_shutdown_behavior = (known after apply)
      + instance_state                       = (known after apply)
      + instance_type                        = "t3.micro"
      ...

Вот так можно переопределять переменные


Кстати, заметим еще одну интересную вещь. Мы так же можем переопределить переменные
с пемощью переменных окружения, т.е.

$ export TF_VAR_instance_type=t3.medium

$ terraform plan

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # aws_instance.my_lemp will be created
  + resource "aws_instance" "my_lemp" {
      + ami                                  = "ami-05f5f4f906feab6a7"
      + arn                                  = (known after apply)
      + associate_public_ip_address          = (known after apply)
      + availability_zone                    = "eu-central-1a"
      + cpu_core_count                       = (known after apply)
      + cpu_threads_per_core                 = (known after apply)
      + disable_api_termination              = (known after apply)
      + ebs_optimized                        = (known after apply)
      + get_password_data                    = false
      + host_id                              = (known after apply)
      + id                                   = (known after apply)
      + instance_initiated_shutdown_behavior = (known after apply)
      + instance_state                       = (known after apply)
      + instance_type                        = "t3.medium"


Таким образом у нас в файле variables.tf переменная instance_type имела значение t2.micro,
а мы ее переопределили с помощью переменной окружения на t3.medium

Не забывайте очистить переменную, если она вам больше не нужна

$ unset TF_VAR_instance_type

$ echo $TF_VAR_instance_type

$

-------------------------------------------------
Переопределение переменных с помощью файла tfvars
-------------------------------------------------

Переменные можно переопределять с помощью файла - terraform.tfvars. Т.е. мы
описываем переменные в нем. Но это не так интересно. Более интересно сделать несколько
по-другому.

Создадим два файла: dev.tfvars prod.tfvars. С их содержимым можно ознакомится в директории с
проектом.

Зпустим plan и обратим внимание на значения instance_type, tags, volume_size и volume_type.
Как мы видми ничего не переопределилось. Как было в файле variables.tf так и осталось.

$ terraform plan

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # aws_instance.my_lemp will be created
  + resource "aws_instance" "my_lemp" {
      ...
      + instance_type                        = "t2.micro"
      ...
      + tags                                 = {
          + "Env"     = "dev"
          + "Name"    = "my_lemp_dev"
          + "Owner"   = "Denis Bochinskii"
          + "Project" = "rocinante"
        }
      ...
      + root_block_device {
          + delete_on_termination = true
          + device_name           = (known after apply)
          + encrypted             = (known after apply)
          + iops                  = (known after apply)
          + kms_key_id            = (known after apply)
          + throughput            = (known after apply)
          + volume_id             = (known after apply)
          + volume_size           = 10
          + volume_type           = "gp3"
        }
    }
    ...

Теперь укажем файл dev.tfvars при выполнении команды plan. Как мы видм, переменные
переопределились значениями в файле - dev.tfvars.

$ terraform plan -var-file="dev.tfvars"

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # aws_instance.my_lemp will be created
  + resource "aws_instance" "my_lemp" {
      ...
      + instance_type                        = "t2.nano"
      ...
      + tags                                 = {
          + "Env"     = "development"
          + "Name"    = "my_lemp_development"
          + "Owner"   = "Denis Bochinskii"
          + "Project" = "rocinante"
        }
      ...
      + root_block_device {
          + delete_on_termination = true
          + device_name           = (known after apply)
          + encrypted             = (known after apply)
          + iops                  = (known after apply)
          + kms_key_id            = (known after apply)
          + throughput            = (known after apply)
          + volume_id             = (known after apply)
          + volume_size           = 8
          + volume_type           = "gp2"
        }
    }
    ...


Теперь укажем файл - prod.tfvars. Как мы видим, значения переменных запимились на те,
которые в файле - prod.tfvars.

$ terraform plan -var-file="prod.tfvars"

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # aws_instance.my_lemp will be created
  + resource "aws_instance" "my_lemp" {
      ...
      + instance_type                        = "t3.large"
      ...
      + tags                                 = {
          + "Env"     = "prodaction"
          + "Name"    = "my_lemp_prodaction"
          + "Owner"   = "Denis Bochinskii"
          + "Project" = "rocinante"
        }
      ...
      + root_block_device {
          + delete_on_termination = true
          + device_name           = (known after apply)
          + encrypted             = (known after apply)
          + iops                  = (known after apply)
          + kms_key_id            = (known after apply)
          + throughput            = (known after apply)
          + volume_id             = (known after apply)
          + volume_size           = 64
          + volume_type           = "io2"
        }
    }
    ...

-----------------------------
Локальные переменные (locals)
-----------------------------

https://www.terraform.io/language/values/locals

Локальные переменные тут рассматриваться не будут. Если мы будем их использовать далее,
то об этом упоменем. Даже из официальной документации можно понять, что локальные
переменные редко используют т.к. они "перенапрягают" код.



--------------------------------------------------------------------------------
Жизненный цикл ресурсов (Life Cicle) на примере ALB, LEMP (nearly zero downtime)
--------------------------------------------------------------------------------

https://www.terraform.io/language/meta-arguments/lifecycle

Есть изменения в ресурсе, которые приводят к удалению сервера и пересозданию.
Выше мы говорили о том, что при изменении user_data ресурс сначала удаляется,
а потом создается новый с новыми user_data. Так же, если в ресурсе изменить ami,
то ресурс тоже пересоздастся.

Есть три вида lifecycle'ов. Первые два редко используются, а вот третий частенько.

Первый вид используется если есть сервера, которые оооооооочень важны.
И их нельзя случайно удалять (пересоздавать). Как же себя защитить?

Вот пример кода

resource "aws_instance" "example" {
  # ...
  # ...

  lifecycle {
    prevent_destroy = true
  }
}

Есть более тонкая настройка (второй вид). Можно перечислить те параметры, которые нужно игнорировать
при повторном apply, если они изменятся.

resource "aws_instance" "example" {
  # ...
  # ...

  lifecycle {
    ignore_changes = ["ami", "user_data"]
  }
}

Последний вид самый интересный. С его помощью можно сделать минимальный простой (nearly zero downtime).
Его используют, когда все таки нужно пересоздать ресурс, но прежде создать такой же.

resource "aws_instance" "example" {
  # ...
  # ...

  lifecycle {
    create_before_destroy = true
  }
}

Вот, как раз последний вид мы будем использовать при установки ALB, LEMP.

Мы создадим ALB, который будет терменировать HTTPS. Так же, все запросы на HTTP
будут перенаправляться на HTTPS.

Создадим один ресурс aws_instance (LEMP), который будет зарегестрирован в
определенной target group'е, к которой привязан наш ALB.

Укажем  create_before_destroy в данном instance'е. Это будет означать,
что если мы изменим, например ami, то сначала создастся новый ec2 instance, а уже потом удалится "старый".
Таким образом у нас будет минимально возможный простой в нашем положении.

Если бы мы не использовали lifecycle, то "старый" ec2 intsance удалился, а потом создался "новый".

$ mkdir ./004_Nearly_Zero_DownTime_LEMP_ALB; cd ./004_Nearly_Zero_DownTime_LEMP_ALB

$ export AWS_ACCESS_KEY_ID=<your access key id>
$ export AWS_SECRET_ACCESS_KEY=<your secret access key>
$ export AWS_DEFAULT_REGION=<your default region>

$ export TF_VAR_ssh_port=<your custome ssh port number>
$ export TF_VAR_mysql_root_pass=<your mysql root password>
$ export TF_VAR_mysql_admin_user=<your mysql admin username>
$ export TF_VAR_mysql_admin_user_pass=<your mysql admin password>
$ export TF_VAR_mysql_drupal_user=<your mysql drupal username>
$ export TF_VAR_mysql_drupal_user_pass=<your mysql drupal user password>
$ export TF_VAR_mysql_drupal_db=<your mysql drupal database>
$ export TF_VAR_site_dir=<your prefix site directory>


Оставим "за кадром" создание конфигурации провайдера.

$ terraform init

С файлом variables.tf и main.tf можно ознакомится в директории с проектом.

В файле variables.tf нет ничего не обычного, кроме переменной:

variable "health_check" {
   type = map
   default = {
     healthy_threshold = "3"
     interval = "10"
     protocol = "HTTP"
     timeout = "2"
     unhealthy_threshold = "2"
     port = "80"
  }
}

мы данный тип переменной знаем и использовалии ранее (в определении тэгов), но
в файле main мы использовали данную переменную по новому:

resource "aws_lb_target_group" "my_lemp_alb_tg" {
..

  health_check {
    enabled = true
    healthy_threshold = var.health_check["healthy_threshold"]
    interval = var.health_check["interval"]
    protocol = var.health_check["protocol"]
    timeout = var.health_check["timeout"]
    unhealthy_threshold = var.health_check["unhealthy_threshold"]
    port = var.health_check["port"]
  }

т.к. map это ключ-значение, то чтобы указать определенное значение, нужно указать переменную и ее ключ.
Например:

interval = var.health_check["interval"]



Далее пробежимся по файлу main.ft более детально.


Как мы уже упоминали ранее, мы создали ресурс aws_instance (my_lemp), по id которого будем
его регестрировать в target group'е. Тут ничего нового, кроме как

subnet_id = var.all_subnet_id[0]

у нас есть переменная - all_subnet_id в которую мы поместили спиок всех subnets'ов
(в нашем случае каждая sunet находится в своей AZ) в данной VPC.
Чтобы выбрать одно значение из списка, мы указали номер - 0 т.е. первое значение в списке.

Для чего мы поместили список всех subnets'ов мы расскажем позже.

Так же в данном ресурсе мы указали

lifecycle {
  create_before_destroy = true
}

эта запись, говорит о том, что прежде чем пересоздать данный ресурс, нужно его сперва создать.

Вот эта запись говорит о том, чтобы происходило перемоздавание ec2 instance'а если изменятся
user data:

user_data_replace_on_change = true

Ну, и ознакомится со скриптом для user data - user_data_http_old.sh.tftpl и user_data_http.sh.tftpl можно так же
в директории с проектом. Они отличаются только версией drupal. Это надо нам для того, чтобы проверить
Nearly Zero Downtime.

Сперва создадим с ресурс с user_data_http_old.sh.tftpl, а потом изменим на user_data_http.sh.tftpl
и посмотрим как заменится ресурс с минимально возможным временем ожидания.


Далее мы создали ресурс aws_lb (my_lemp_alb). Указали ему id группы безопасности, которую
мы создадим позже:

security_groups    = [aws_security_group.my_lemp_alb_sg.id]

и указали все наши subnets'сы

subnets            = var.all_subnet_id

Для чего это делать? У нас же один ресурс только. Все дело в том, что ALB дожен
пренадлежать более чем одной AZ. Поэтому мы решили указать все подсети, которые находятся
в своих AZ.


Далее, мы создали ресурс aws_lb_target_group (my_lemp_alb_tg) для создания target group'ы.
В которую мы поместим ec2 instance.


С помощью ресурса aws_lb_target_group_attachment (my_lemp_alb_tg_attach) мы указали,
что "наша" target group'а должна будет регестрировать "наш" ec2 instance.



Далее, мы создали listeners'ы для нашего ALB - aws_lb_listener (my_lemp_alb_listener_80,
my_lemp_alb_listener_443). В первом ресурсе мы сделали редирект на HTTPS.
Во втором listener'е мы указали, что все запросы идут в "нашу" target group'у.

Так же мы указали ранее созданный в Certificate Manager'е сертификат для HTTPS.

Далее мы создали ресурсы групп безопасности. Одна группа для ALB, которая принемает
трафик от всех на 80 и 443 порты. Так же сделали группы безопасности для ec2 instance'а,
одна пропускают весь трафик от ALB, а  вторая от всех на SSH порты.

Несколько слов об outputs.tf.

С помощью outputs мы получили интересующие нас данные по нашим ресурсам.


Теперь можно запустить:


$ terraform plan

$ terraform apply

...

Outputs:

aws_instance_my_lemp_public_dns = "ec2-18-185-49-15.eu-central-1.compute.amazonaws.com"
aws_instance_my_lemp_public_ip = "18.185.49.15"
my_lemp_alb_dns = "my-lemp-alb-179365732.eu-central-1.elb.amazonaws.com"
target_group_arn = "arn:aws:elasticloadbalancing:eu-central-1:880954070217:targetgroup/my-lemp-alb-tg/265536a44a7ecac7"




Теперь давайте заменим, например файл user data с user_data_http_old.sh.tftpl на user_data_http.sh.tftpl.

Снова запускаем снова

$ terraform plan

$ terraform apply

...

Outputs:

aws_instance_my_lemp_public_dns = "ec2-3-71-53-239.eu-central-1.compute.amazonaws.com"
aws_instance_my_lemp_public_ip = "3.71.53.239"
my_lemp_alb_dns = "my-lemp-alb-179365732.eu-central-1.elb.amazonaws.com"
target_group_arn = "arn:aws:elasticloadbalancing:eu-central-1:880954070217:targetgroup/my-lemp-alb-tg/265536a44a7ecac7"



Если паралельно посмотреть в AWS консоль, то можно заметить, что сперва создается
и регестрируется в target group "новый "ec2 instance, а уже потом удаляется
регестрация и удаляется "старый" ec2 instance.


На самом деле, очень много времени тратится на used data. Если вы посмотрите на скрипт,
то увидите, что там много всего устанавливается. В реальных условиях, лучше сделать
свой ami с предустановленным - lemp. Тогда будет все намного быстрее и простой
уменьшится во много раз.

$ terraform destroy


--------------------------------
Получение данных из Data Sources
--------------------------------

Мы уже использовали Data Sources ранее. Когда создавали ресурсы и указывали из id
в другом ресурсе. Но можно так же "вытаскивать" информацию из ресурсов, которые мы не создавали
в проекте.

На примере будет понятней.

$ mkdir ./005_Data_Sources; cd ./005_Data_Sources

$ export AWS_ACCESS_KEY_ID=<your access key id>
$ export AWS_SECRET_ACCESS_KEY=<your secret access key>
$ export AWS_DEFAULT_REGION=<your default region>

$ export TF_VAR_ssh_port=<your custome ssh port number>
$ export TF_VAR_mysql_root_pass=<your mysql root password>
$ export TF_VAR_mysql_admin_user=<your mysql admin username>
$ export TF_VAR_mysql_admin_user_pass=<your mysql admin password>
$ export TF_VAR_mysql_drupal_user=<your mysql drupal username>
$ export TF_VAR_mysql_drupal_user_pass=<your mysql drupal user password>
$ export TF_VAR_mysql_drupal_db=<your mysql drupal database>
$ export TF_VAR_site_dir=<your prefix site directory>

Оставим "за кадром" создание конфигурации провайдера.

$ terraform init

$ touch data_sources.tf

Ознакомится с данным файлом можно в директории с проектом.

----------------
Информация о AZs
----------------

https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/availability_zones

Рассмотрим вот эти строчки:

data "aws_availability_zones" "available" {
  state = "available"
}

output "data_aws_availability_zones_available"{
  value = data.aws_availability_zones.available
}

data - эта конфигурация говорит о том, что мы вытаскиваем информацию обо всех
AZ, в нашем регионе.

state = "available" - это фильтр, т.к. вытащить всю информацию для AZ, которые доступны.

С помощью output мы выводим всю информацию на экран

$ terraform plan

Changes to Outputs:
  + data_aws_availability_zones_available = {
      + all_availability_zones = null
      + exclude_names          = null
      + exclude_zone_ids       = null
      + filter                 = null
      + group_names            = [
          + "eu-central-1",
        ]
      + id                     = "eu-central-1"
      + names                  = [
          + "eu-central-1a",
          + "eu-central-1b",
          + "eu-central-1c",
        ]
      + state                  = "available"
      + zone_ids               = [
          + "euc1-az2",
          + "euc1-az3",
          + "euc1-az1",
        ]
    }

Посмотрев всю информацию, которую можно изъять из Data Source или посмотреть ее в документации,
можно вывести что-то определенное:

output "data_aws_availability_zones_available_names"{
  value = data.aws_availability_zones.available.names
}

$ terraform plan

...
+ data_aws_availability_zones_available_names = [
      + "eu-central-1a",
      + "eu-central-1b",
      + "eu-central-1c",
    ]

Или можно вывести еще определенней :)

output "data_aws_availability_zones_available_first_name"{
  value = data.aws_availability_zones.available.names[0]
}

0 - это номер элемента в списке


$ terraform plan

...
+ data_aws_availability_zones_available_first_name = "eu-central-1a"
...

В файле для примера, есть те Data Sources, которые часто используются в реальных проектах.
Можете с ними ознакомится.

Так же приведу ссылки на документацию:

https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/caller_identity

https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/region

https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/vpcs

https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/vpc



--------------------------------------
Создание subnets'ов в существующей VPC
--------------------------------------

Как вы могли догадаться, информацию из Data Sources можно не только выводить,
но и использовать при создании ресурсов.

Для примера, допустим у нас задание: есть созданная VPC с тэгом - prod,
нужно в ней создать 2 subnets'ы в двух разных AZ (a, b).

Вы можете временно закомментировать файл data_sources.tf.

Так же отметим, что для простоты, мы все описали в файле - maint.tf.

Вот так мы изъяли информацию из Data Sources отфилтровав ее по тэгу - prod.

data "aws_vpc" "prod" {
  tags = {
    Name = "prod"
  }
}

Так же мы изъяли некторую другую информацию, которая нам понадобится.

В ресурсах aws_subnet (prod_1aб prod_1b) ми использовали данную информацию.


Так же, с помощью outputs мы вывели важную информацию, которая нам может быть понадобится
в будущем.

Выполняем:

$ terraform plan

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # aws_subnet.prod_1a will be created
  + resource "aws_subnet" "prod_1a" {
      + arn                                            = (known after apply)
      + assign_ipv6_address_on_creation                = false
      + availability_zone                              = "eu-central-1a"
      + availability_zone_id                           = (known after apply)
      + cidr_block                                     = "10.0.0.0/24"
      + enable_dns64                                   = false
      + enable_resource_name_dns_a_record_on_launch    = false
      + enable_resource_name_dns_aaaa_record_on_launch = false
      + id                                             = (known after apply)
      + ipv6_cidr_block_association_id                 = (known after apply)
      + ipv6_native                                    = false
      + map_public_ip_on_launch                        = false
      + owner_id                                       = (known after apply)
      + private_dns_hostname_type_on_launch            = (known after apply)
      + tags                                           = {
          + "Account" = "880954070217"
          + "Name"    = "prod_eu-central-1a"
        }
      + tags_all                                       = {
          + "Account" = "880954070217"
          + "Name"    = "prod_eu-central-1a"
        }
      + vpc_id                                         = "vpc-030d3173063a3ea8e"
    }

  # aws_subnet.prod_1b will be created
  + resource "aws_subnet" "prod_1b" {
      + arn                                            = (known after apply)
      + assign_ipv6_address_on_creation                = false
      + availability_zone                              = "eu-central-1b"
      + availability_zone_id                           = (known after apply)
      + cidr_block                                     = "10.0.1.0/24"
      + enable_dns64                                   = false
      + enable_resource_name_dns_a_record_on_launch    = false
      + enable_resource_name_dns_aaaa_record_on_launch = false
      + id                                             = (known after apply)
      + ipv6_cidr_block_association_id                 = (known after apply)
      + ipv6_native                                    = false
      + map_public_ip_on_launch                        = false
      + owner_id                                       = (known after apply)
      + private_dns_hostname_type_on_launch            = (known after apply)
      + tags                                           = {
          + "Account" = "880954070217"
          + "Name"    = "prod_eu-central-1b"
        }
      + tags_all                                       = {
          + "Account" = "880954070217"
          + "Name"    = "prod_eu-central-1b"
        }
      + vpc_id                                         = "vpc-030d3173063a3ea8e"
    }

Plan: 2 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + aws_subnet_prod_1a_cidr_block = "10.0.0.0/24"
  + aws_subnet_prod_1a_id         = (known after apply)
  + aws_subnet_prod_1b_cidr_block = "10.0.1.0/24"
  + aws_subnet_prod_1b_id         = (known after apply)
  + data_aws_vpc_prod_id          = "vpc-030d3173063a3ea8e"


  $ terraform apply

  Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
    + create

  Terraform will perform the following actions:

    # aws_subnet.prod_1a will be created
    + resource "aws_subnet" "prod_1a" {
        + arn                                            = (known after apply)
        + assign_ipv6_address_on_creation                = false
        + availability_zone                              = "eu-central-1a"
        + availability_zone_id                           = (known after apply)
        + cidr_block                                     = "10.0.0.0/24"
        + enable_dns64                                   = false
        + enable_resource_name_dns_a_record_on_launch    = false
        + enable_resource_name_dns_aaaa_record_on_launch = false
        + id                                             = (known after apply)
        + ipv6_cidr_block_association_id                 = (known after apply)
        + ipv6_native                                    = false
        + map_public_ip_on_launch                        = false
        + owner_id                                       = (known after apply)
        + private_dns_hostname_type_on_launch            = (known after apply)
        + tags                                           = {
            + "Account" = "880954070217"
            + "Name"    = "prod_eu-central-1a"
          }
        + tags_all                                       = {
            + "Account" = "880954070217"
            + "Name"    = "prod_eu-central-1a"
          }
        + vpc_id                                         = "vpc-030d3173063a3ea8e"
      }

    # aws_subnet.prod_1b will be created
    + resource "aws_subnet" "prod_1b" {
        + arn                                            = (known after apply)
        + assign_ipv6_address_on_creation                = false
        + availability_zone                              = "eu-central-1b"
        + availability_zone_id                           = (known after apply)
        + cidr_block                                     = "10.0.1.0/24"
        + enable_dns64                                   = false
        + enable_resource_name_dns_a_record_on_launch    = false
        + enable_resource_name_dns_aaaa_record_on_launch = false
        + id                                             = (known after apply)
        + ipv6_cidr_block_association_id                 = (known after apply)
        + ipv6_native                                    = false
        + map_public_ip_on_launch                        = false
        + owner_id                                       = (known after apply)
        + private_dns_hostname_type_on_launch            = (known after apply)
        + tags                                           = {
            + "Account" = "880954070217"
            + "Name"    = "prod_eu-central-1b"
          }
        + tags_all                                       = {
            + "Account" = "880954070217"
            + "Name"    = "prod_eu-central-1b"
          }
        + vpc_id                                         = "vpc-030d3173063a3ea8e"
      }

  Plan: 2 to add, 0 to change, 0 to destroy.

  Changes to Outputs:
    + aws_subnet_prod_1a_cidr_block = "10.0.0.0/24"
    + aws_subnet_prod_1a_id         = (known after apply)
    + aws_subnet_prod_1b_cidr_block = "10.0.1.0/24"
    + aws_subnet_prod_1b_id         = (known after apply)
    + data_aws_vpc_prod_id          = "vpc-030d3173063a3ea8e"

  Do you want to perform these actions?
    Terraform will perform the actions described above.
    Only 'yes' will be accepted to approve.

    Enter a value: yes

  aws_subnet.prod_1a: Creating...
  aws_subnet.prod_1b: Creating...
  aws_subnet.prod_1b: Creation complete after 3s [id=subnet-0798dbc8563630efd]
  aws_subnet.prod_1a: Creation complete after 3s [id=subnet-06cd3f2d09631dd2c]

  Apply complete! Resources: 2 added, 0 changed, 0 destroyed.

  Outputs:

  aws_subnet_prod_1a_cidr_block = "10.0.0.0/24"
  aws_subnet_prod_1a_id = "subnet-06cd3f2d09631dd2c"
  aws_subnet_prod_1b_cidr_block = "10.0.1.0/24"
  aws_subnet_prod_1b_id = "subnet-0798dbc8563630efd"
  data_aws_vpc_prod_id = "vpc-030d3173063a3ea8e"
